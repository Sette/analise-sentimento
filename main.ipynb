{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import nltk\n",
    "\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "\n",
    "#Carregando corpus\n",
    "with open('base.csv', 'r') as ficheiro:\n",
    "    reader = csv.reader(ficheiro, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    base = [linha for linha in reader]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Extraindo radical das palavras e removendo stopwors\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "frases = []\n",
    "for (palavras,emocao) in base:\n",
    "    semstemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in stopwords]\n",
    "    frases.append((semstemming, emocao))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Extraindo palavras\n",
    "allWords = []\n",
    "for (palavras,emocao) in frases:\n",
    "    allWords.extend(palavras)\n",
    "#Eliminando repetição de palavras\n",
    "allWords = nltk.FreqDist(allWords).keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'admir': {True}, 'muit': {True}, 'sint': {False}, 'complet': {False}, 'am': {False}, 'maravilh': {False}, 'sent': {False}, 'anim': {False}, 'nov': {False}, 'bem': {False}, 'hoj': {False}, 'bel': {False}, 'dia': {False}, 'dirig': {False}, 'carr': {False}, 'bonit': {False}, 'cont': {False}, 'result': {False}, 'test': {False}, 'fiz': {False}, 'ont': {False}, 'lind': {False}, 'amizad': {False}, 'vai': {False}, 'dur': {False}, 'sempr': {False}, 'amedront': {False}, 'ameac': {False}, 'deix': {False}, 'apavor': {False}, 'lug': {False}, 'perd': {False}, 'outr': {False}, 'jog': {False}, 'elimin': {False}, 'pav': {False}, 'descobr': {False}, 'encrenc': {False}, 'trem': {False}, 'med': {False}}, 'alegria'), ({'admir': {False}, 'muit': {False}, 'sint': {True}, 'complet': {True}, 'am': {True}, 'maravilh': {False}, 'sent': {False}, 'anim': {False}, 'nov': {False}, 'bem': {False}, 'hoj': {False}, 'bel': {False}, 'dia': {False}, 'dirig': {False}, 'carr': {False}, 'bonit': {False}, 'cont': {False}, 'result': {False}, 'test': {False}, 'fiz': {False}, 'ont': {False}, 'lind': {False}, 'amizad': {False}, 'vai': {False}, 'dur': {False}, 'sempr': {False}, 'amedront': {False}, 'ameac': {False}, 'deix': {False}, 'apavor': {False}, 'lug': {False}, 'perd': {False}, 'outr': {False}, 'jog': {False}, 'elimin': {False}, 'pav': {False}, 'descobr': {False}, 'encrenc': {False}, 'trem': {False}, 'med': {False}}, 'alegria'), ...]\n"
     ]
    }
   ],
   "source": [
    "#Montando tabela de atributo-valor\n",
    "def extratordepalavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in allWords:\n",
    "        caracteristicas['%s' % palavras] = {palavras in doc}\n",
    "    return caracteristicas\n",
    "\n",
    "\n",
    "basecompleta = nltk.classify.apply_features(extratordepalavras,frases)\n",
    "print(basecompleta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classificador = nltk.Naive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
